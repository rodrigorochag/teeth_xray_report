model: gpt-5.2
prompt_name: prompt_missing
max_output_tokens: 256