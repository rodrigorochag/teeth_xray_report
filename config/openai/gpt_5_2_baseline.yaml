model: gpt-5.2
prompt_name: baseline_prompt
max_output_tokens: 256