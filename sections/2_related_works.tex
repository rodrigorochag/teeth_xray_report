
\section{Related Works}

The application of deep learning in medical imaging encompasses a number of fundamental tasks. Classification models assign a categorical label to an entire image, such as determining the presence or absence of individual teeth. The work of Mendes \textit{et al.}~\cite{mendes2025automated} investigated the application of the YOLOv8 model for the automated detection and numbering of teeth in panoramic radiographs. Their study was conducted on the DENTEX \cite{hamamci2023dentexabnormaltoothdetection} dataset, which consists of 637 panoramic images, and employed k-fold cross-validation to ensure the reliability of the results. The best-performing model, YOLOv8x, achieved a precision of 0.9283, a recall of 0.9327, and a mAP50-95 of 0.5657. The results demonstrate that the YOLOv8 model is a robust and effective tool for automating tooth detection, with the potential to improve diagnostic efficiency and accuracy in dental practice.

Zhang \textit{et al.} \cite{zhang2023children} introduced the first public dataset of children's dental panoramic radiographs for caries segmentation and dental disease detection, addressing the lack of such resources for pediatric dentistry. The dataset contains 100 high-quality panoramic radiographs from patients aged 2 to 13, annotated for both tooth segmentation and various dental diseases like caries, periodontitis, and pulpitis. The authors also provided an additional 93 pediatric images and compiled 2,692 adult radiographs from existing public datasets to create a comprehensive segmentation resource. To validate the dataset's utility, they conducted experiments using established deep learning models such as U-Net, which achieved high performance with a mean IoU of 0.8858 on the adult's data. 

In a 2025 study, Xiong \textit{et al.} \cite{xiong2025exploring} evaluated the multimodal reasoning capabilities of GPT-4o on panoramic radiographs by tasking it with identifying inserted errors in radiological findings. The study included 230 panoramic radiographs, and various prompt engineering strategies were tested to enhance the model's performance. While a zero-shot approach yielded a recall of 43.33\%, a "meta-prompt" integrating multiple strategies like chain-of-thought and multimodal in-context learning improved the recall to 52.67\% and accuracy to 68.75\%. The authors also found a significant correlation between the model's localization accuracy (45.67\%) and its reasoning capability. Despite improvements through prompt engineering, the study concluded that GPT-4o's performance is not yet adequate for clinical use.

\textcolor{red}{Adicionar outros trabalhos (pelo menos 2 mais...), falar dos datasets publicos? Quando se fala ``et al.'' na citação se coloca em italico.}