\section{Introduction}


Medical imaging is fundamental to the practice of modern diagnostic medicine. Modalities such as Computed Tomography (CT), Magnetic Resonance Imaging (MRI), ultrasound, and radiography are prevalent tools in contemporary clinical practice. In the dental field, panoramic radiographs are particularly vital as they are clinically used for a wide range of diagnostic tasks. These include the detection of jaw fractures, the assessment of the location and position of third molars, the identification of dental or bone disease, the location of root remnants, the evaluation of affected teeth, the diagnosis of dislocation of the temporomandibular joint (TMJ) and the identification of other dental abnormalities and surrounding tissue pathologies. 
Automated analysis of such medical images using artificial intelligence (AI) has demonstrated significant advances~\cite{litjens2017survey}. In this sense, recent research indicates that AI-driven analysis can achieve improved performance compared to conventional techniques and, in some cases, may even surpass the diagnostic accuracy of experienced radiologists~\cite{shen2017deep}. Therefore, the integration of automated methods and AI-assisted healthcare systems stands to significantly enhance the speed and efficiency of these diagnostic analyses \cite{sunilkumar2024recent}.

Within the context of AI-driven dental analysis, two of the primary computer vision tasks applied to medical imaging are object detection and semantic segmentation. Object detection models, such as those in the You Only Look Once (YOLO)~\cite{redmon2016you} family, are trained to localize regions of interest (e.g., a specific tooth or pathology) by predicting bounding boxes. Segmentation networks, conversely, are designed to perform a more granular task: classifying every pixel in an image to delineate the precise shape and boundary of an object. However, a critical bottleneck for developing these supervised models is the high cost associated with data annotation. While the manual creation of bounding boxes for detection tasks is time-consuming, the generation of accurate, pixel-level masks for segmentation is substantially more labor-intensive and expensive. This annotation process must be performed by clinical experts to ensure anatomical and pathological fidelity, making dataset curation a significant financial and logistical challenge.
To address this, foundational models have emerged that can mitigate the annotation burden. Recent models such as Segment Anything Model (SAM)~\cite{kirillov2023segment} shows unprecedented capacity for zero-shot generalization. Trained on the massive SA-1B dataset, containing over one billion masks, SAM learned a general concept of an object, enabling it to effectively segment items and structures in images and domains that were not seen during its training. This generalization capability has direct and significant implications for reducing the cost of annotation, which is a notorious bottleneck in the development of deep learning models.

%% Report with AI

Panoramic radiograph reports are an essential component of comprehensive dental diagnostic procedures, providing essential information on the maxillofacial complex, including the dentition, alveolar bone, and associated anatomical structures. The utility of these reports is critical for accurate diagnosis, systemic condition screening, and effective treatment planning. However, manual interpretation and subsequent generation of detailed reports present significant challenges; the process is time-consuming, resource-intensive, and susceptible to inter-observer variability and human perceptual errors, which may lead to diagnostic oversights. Artificial Intelligence (AI), particularly through deep learning algorithms, offers a transformative solution to these limitations \cite{schwendicke2020artificial}. AI-driven decision support systems can automate the detection and segmentation of pathologies—such as caries, periapical lesions, and bone-level anomalies—thereby enhancing diagnostic precision and consistency \cite{wang2019pathology}. By streamlining analytics and helping generate structured reports, AI facilitates a more efficient clinical workflow, reduces the burden on clinicians, and ultimately can help raise the standard of patient care. 

Large Language Models (LLMs) represent a significant paradigm shift in artificial intelligence, characterized by their massive scale and sophisticated deep learning architectures, typically Transformers, trained on extensive text corpora \cite{naveed2025comprehensive}. These models have demonstrated remarkable proficiency in understanding, processing, and generating human-like language. Functionally, LLMs operate by processing user-supplied textual inputs, known as "prompts," which define a specific task or query. In response to these prompts, the models generate coherent and contextually relevant outputs, thereby enabling them to serve as versatile tools for complex tasks such as automated question-answering, data synthesis, and task execution. However, these models can present challenges to real-word usage in the context of odontology: ChatGPT, a popular LLM, exhibits significant generation of factually incorrect responses, nonsensical outputs, and the propensity to present misinformation authoritatively \cite{eggmann2023implications}.

\textcolor{blue}{Therefore, in this work we ... Explicar o que foi proposto no trabalho, e adicionar um outro parágrafo falando dos que vai ser mostrado nos proximos capitulos} 

This study proposes a multimodal pipeline for the analysis of panoramic radiographs. The methodology integrates the YOLOv12x architecture for object detection and the Segment Anything Model (SAM1-FT) for segmentation. Furthermore, this work investigates the capacity of the Large Language Model (LLM) to identify characteristics and anomalies in panoramic radiographs by processing the segmented images and structured JSON data.

The remainder of this work is organized as follows. Chapter 2 presents the Related Works regarding deep learning applications in dentistry. Chapter 3 details the Materials and Methods, covering data collection, annotation, and the definition of clinical report and segmented data. This chapter also describes the methodologies for transforming simple labels into bounding boxes and the pre-processing framework, including data augmentation strategies. Furthermore, it outlines the clinical report pipeline and the classification procedures utilizing ChatGPT-5. Chapter 4 presents the experimental Results. Finally, Chapter 5 provides the Discussion of the findings.